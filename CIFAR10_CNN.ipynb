{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR10 - CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joelcapistrano/cifar10-cnn/blob/master/CIFAR10_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvt4CwqUeRQa",
        "colab_type": "text"
      },
      "source": [
        "# **Convolutional Neural Network for CIFAR10**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qq5_o0bHy6Se",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-K-zzFFg0H4v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dense, Dropout\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "from tensorflow.keras.datasets import cifar10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CN_-cFwMPdIK",
        "colab_type": "text"
      },
      "source": [
        "Load CIFAR10 dataset and prepare training/test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzBENHjE0RNv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "c92a0000-976d-4179-c7a5-48390869bba8"
      },
      "source": [
        "# Load CIFAR10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Get number of labels\n",
        "num_labels = len(np.unique(y_train))\n",
        "\n",
        "# Convert labels to one-hot vector\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# Get image dimension (image is assumed to be square)\n",
        "image_size = x_train.shape[1]\n",
        "\n",
        "# Image to be processed as is (Square RGB)\n",
        "input_shape = (image_size, image_size, 3)\n",
        "\n",
        "# Normalize image values\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rP8-R9saHFzt",
        "colab_type": "text"
      },
      "source": [
        "The CNN Architecture has **three Conv2D layers** using the same kernel size and activation function. A function is set up to facilitate **hyperparameter tuning** (filters and dropout). **Categorical Crossentropy** is chosen as the loss function and **Accuracy** is chosen as the metric since the CNN will perform **single label classification** (i.e. only one label can be correct)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2opC0_BlIIl6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# CNN Architecture\n",
        "# Conv2D-Conv2D-Conv2D-Flatten-Dense-Activation\n",
        "# Batch Size set to 128\n",
        "# 20 Epochs for each training/tuning run\n",
        "def run_model(filters, dropout):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(filters=filters,\n",
        "                   kernel_size=3,\n",
        "                   activation='relu',\n",
        "                   input_shape=input_shape))\n",
        "  model.add(MaxPooling2D(2))\n",
        "  model.add(Conv2D(filters=filters,\n",
        "                   kernel_size=3,\n",
        "                   activation='relu'))\n",
        "  model.add(MaxPooling2D(2))\n",
        "  model.add(Conv2D(filters=filters,\n",
        "                   kernel_size=3,\n",
        "                   activation='relu'))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dropout(dropout))\n",
        "  model.add(Dense(num_labels))\n",
        "  model.add(Activation('softmax'))\n",
        "  model.summary()\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer='adam', \n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  model.fit(x_train, y_train, epochs=20, batch_size=128)\n",
        "  train_score = model.evaluate(x_train, y_train, batch_size=128)\n",
        "  print(\"\\nTrain accuracy: %.1f%%\" % (100.0 * train_score[1]))\n",
        "  test_score = model.evaluate(x_test, y_test, batch_size=128)\n",
        "  print(\"\\nTest accuracy: %.1f%%\" % (100.0 * test_score[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkLqXk3y0jsG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b703986e-f952-49e7-a701-63c59c7c28da"
      },
      "source": [
        "# Set filters to 64 and dropout to 0.2\n",
        "run_model(64, 0.2)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 30, 30, 64)        1792      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 4, 4, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                10250     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 85,898\n",
            "Trainable params: 85,898\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 6s 126us/sample - loss: 1.6885 - acc: 0.3817\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 6s 121us/sample - loss: 1.3625 - acc: 0.5119\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 6s 122us/sample - loss: 1.2366 - acc: 0.5624\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 6s 123us/sample - loss: 1.1288 - acc: 0.6032\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 6s 121us/sample - loss: 1.0521 - acc: 0.6293\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 6s 120us/sample - loss: 0.9979 - acc: 0.6506\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 6s 121us/sample - loss: 0.9496 - acc: 0.6664\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 6s 121us/sample - loss: 0.8980 - acc: 0.6863\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 6s 121us/sample - loss: 0.8703 - acc: 0.6967\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 6s 121us/sample - loss: 0.8388 - acc: 0.7076\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 6s 121us/sample - loss: 0.8164 - acc: 0.7176\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 6s 121us/sample - loss: 0.7903 - acc: 0.7261\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 6s 120us/sample - loss: 0.7680 - acc: 0.7333\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 6s 121us/sample - loss: 0.7472 - acc: 0.7401\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 6s 121us/sample - loss: 0.7265 - acc: 0.7468\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 6s 121us/sample - loss: 0.7106 - acc: 0.7518\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 6s 121us/sample - loss: 0.6907 - acc: 0.7587\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 6s 122us/sample - loss: 0.6741 - acc: 0.7630\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 6s 121us/sample - loss: 0.6619 - acc: 0.7672\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 6s 122us/sample - loss: 0.6491 - acc: 0.7735\n",
            "50000/50000 [==============================] - 3s 61us/sample - loss: 0.5616 - acc: 0.8076\n",
            "\n",
            "Train accuracy: 80.8%\n",
            "10000/10000 [==============================] - 1s 65us/sample - loss: 0.7827 - acc: 0.7356\n",
            "\n",
            "Test accuracy: 73.6%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdVcZK6fPGjj",
        "colab_type": "text"
      },
      "source": [
        "With filters set to 64 and dropout set to 0.2, Training Data Accuracy is 80.8% and Test Data Accuracy is 73.6%. Next step is to see if accuracy will improve as we increase the number of filters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtIKtbeROTfi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8c107df8-8439-4aea-c0bf-decbb83531ba"
      },
      "source": [
        "# Set filters to 128 and dropout to 0.2\n",
        "run_model(128, 0.2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 30, 30, 128)       3584      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 15, 15, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 13, 13, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 4, 4, 128)         147584    \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                20490     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 319,242\n",
            "Trainable params: 319,242\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 10s 209us/sample - loss: 1.5932 - acc: 0.4220\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 10s 200us/sample - loss: 1.2420 - acc: 0.5588\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 10s 203us/sample - loss: 1.0832 - acc: 0.6209\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 10s 201us/sample - loss: 0.9831 - acc: 0.6568\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 10s 200us/sample - loss: 0.9079 - acc: 0.6850\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 10s 201us/sample - loss: 0.8477 - acc: 0.7047\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 10s 200us/sample - loss: 0.7913 - acc: 0.7243\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 10s 200us/sample - loss: 0.7548 - acc: 0.7397\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 10s 199us/sample - loss: 0.7102 - acc: 0.7542\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 10s 200us/sample - loss: 0.6801 - acc: 0.7624\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 10s 201us/sample - loss: 0.6509 - acc: 0.7727\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 10s 199us/sample - loss: 0.6156 - acc: 0.7847\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 10s 200us/sample - loss: 0.5967 - acc: 0.7926\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 10s 199us/sample - loss: 0.5669 - acc: 0.8025\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 10s 201us/sample - loss: 0.5371 - acc: 0.8134\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 10s 200us/sample - loss: 0.5095 - acc: 0.8225\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 10s 201us/sample - loss: 0.4912 - acc: 0.8274\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 10s 201us/sample - loss: 0.4669 - acc: 0.8354\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 10s 202us/sample - loss: 0.4514 - acc: 0.8420\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 10s 200us/sample - loss: 0.4261 - acc: 0.8489\n",
            "50000/50000 [==============================] - 5s 90us/sample - loss: 0.3166 - acc: 0.8952\n",
            "\n",
            "Train accuracy: 89.5%\n",
            "10000/10000 [==============================] - 1s 92us/sample - loss: 0.7802 - acc: 0.7557\n",
            "\n",
            "Test accuracy: 75.6%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnlPVt4PQQso",
        "colab_type": "text"
      },
      "source": [
        "With filters set to 128 and dropout set to 0.2, Training Data Accuracy increased to 89.5% and Test Data Accuracy increased to 75.6%. We again check if accuracy will still improve as we further increase the number of filters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FopmW8LTQu8k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "54c6ee06-eaf3-46e0-eb10-ba1abe2c9f8e"
      },
      "source": [
        "# Set filters to 256 and dropout to 0.2\n",
        "run_model(256, 0.2)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 30, 30, 256)       7168      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 15, 15, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 13, 13, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 4, 4, 256)         590080    \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                40970     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,228,298\n",
            "Trainable params: 1,228,298\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 20s 409us/sample - loss: 1.5767 - acc: 0.4256\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 20s 394us/sample - loss: 1.1887 - acc: 0.5824\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 20s 393us/sample - loss: 1.0052 - acc: 0.6516\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 20s 391us/sample - loss: 0.8959 - acc: 0.6884\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 20s 392us/sample - loss: 0.8036 - acc: 0.7206\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 20s 392us/sample - loss: 0.7447 - acc: 0.7404\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 20s 392us/sample - loss: 0.6906 - acc: 0.7596\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 20s 392us/sample - loss: 0.6431 - acc: 0.7765\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 20s 391us/sample - loss: 0.5938 - acc: 0.7934\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 20s 391us/sample - loss: 0.5497 - acc: 0.8066\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 20s 391us/sample - loss: 0.5136 - acc: 0.8208\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 19s 390us/sample - loss: 0.4832 - acc: 0.8298\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 20s 392us/sample - loss: 0.4516 - acc: 0.8429\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 19s 390us/sample - loss: 0.4132 - acc: 0.8538\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 20s 393us/sample - loss: 0.3905 - acc: 0.8633\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 20s 391us/sample - loss: 0.3665 - acc: 0.8692\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 20s 390us/sample - loss: 0.3420 - acc: 0.8779\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 20s 391us/sample - loss: 0.3101 - acc: 0.8890\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 20s 401us/sample - loss: 0.2943 - acc: 0.8943\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 20s 396us/sample - loss: 0.2837 - acc: 0.8973\n",
            "50000/50000 [==============================] - 8s 153us/sample - loss: 0.1582 - acc: 0.9526\n",
            "\n",
            "Train accuracy: 95.3%\n",
            "10000/10000 [==============================] - 2s 158us/sample - loss: 0.8225 - acc: 0.7660\n",
            "\n",
            "Test accuracy: 76.6%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aOLolDNRVuI",
        "colab_type": "text"
      },
      "source": [
        "With filters set to 256 and dropout set to 0.2, Training Data Accuracy increased to 95.3% and Test Data Accuracy increased to 76.6%. We again check if accuracy will still improve as we further increase the number of filters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzY6ft25RcIQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "19cc7d09-107a-43a9-f02a-063c4234c828"
      },
      "source": [
        "# Set filters to 512 and dropout to 0.2\n",
        "run_model(512, 0.2)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 30, 30, 512)       14336     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 15, 15, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 13, 13, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 6, 6, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 4, 4, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                81930     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 4,815,882\n",
            "Trainable params: 4,815,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 50s 995us/sample - loss: 1.5300 - acc: 0.4415\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 47s 937us/sample - loss: 1.1067 - acc: 0.6126\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 47s 938us/sample - loss: 0.9229 - acc: 0.6794\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 47s 937us/sample - loss: 0.8007 - acc: 0.7222\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 47s 938us/sample - loss: 0.7143 - acc: 0.7531\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 47s 935us/sample - loss: 0.6275 - acc: 0.7825\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 47s 935us/sample - loss: 0.5606 - acc: 0.8048\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 47s 936us/sample - loss: 0.4954 - acc: 0.8267\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 47s 936us/sample - loss: 0.4419 - acc: 0.8459\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 47s 936us/sample - loss: 0.3861 - acc: 0.8648\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 47s 935us/sample - loss: 0.3416 - acc: 0.8788\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 47s 936us/sample - loss: 0.3074 - acc: 0.8908\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 47s 936us/sample - loss: 0.2653 - acc: 0.9063\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 47s 935us/sample - loss: 0.2323 - acc: 0.9171\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 47s 935us/sample - loss: 0.2122 - acc: 0.9259\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 47s 935us/sample - loss: 0.1887 - acc: 0.9331\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 47s 940us/sample - loss: 0.1719 - acc: 0.9398\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 47s 939us/sample - loss: 0.1593 - acc: 0.9423\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 47s 938us/sample - loss: 0.1499 - acc: 0.9468\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 47s 939us/sample - loss: 0.1387 - acc: 0.9512\n",
            "50000/50000 [==============================] - 17s 350us/sample - loss: 0.1157 - acc: 0.9592\n",
            "\n",
            "Train accuracy: 95.9%\n",
            "10000/10000 [==============================] - 4s 363us/sample - loss: 1.2878 - acc: 0.7327\n",
            "\n",
            "Test accuracy: 73.3%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0VqkbtIRfgD",
        "colab_type": "text"
      },
      "source": [
        "With filters set to 512 and dropout set to 0.2, Training Data Accuracy increased to 95.9% but Test Data Accuracy decreased to 73.3%. We take a step back and choose 256 as the number of filters since it generated the highest Test Data Accuracy (before it started to decrease). Next step is to see if accuracy will improve as we increase the dropout value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9dmsH5cSyQC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ab9068c0-6bbe-448c-8182-d844a86863ff"
      },
      "source": [
        "# Set filters to 256 and dropout to 0.4\n",
        "run_model(256, 0.4)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_15 (Conv2D)           (None, 30, 30, 256)       7168      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 15, 15, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 13, 13, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 4, 4, 256)         590080    \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                40970     \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,228,298\n",
            "Trainable params: 1,228,298\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 20s 406us/sample - loss: 1.6064 - acc: 0.4125\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 20s 401us/sample - loss: 1.2206 - acc: 0.5662\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 20s 404us/sample - loss: 1.0536 - acc: 0.6304\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 20s 403us/sample - loss: 0.9567 - acc: 0.6649\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 20s 402us/sample - loss: 0.8814 - acc: 0.6922\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 20s 402us/sample - loss: 0.8062 - acc: 0.7189\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 20s 401us/sample - loss: 0.7584 - acc: 0.7372\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 20s 401us/sample - loss: 0.7188 - acc: 0.7505\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 20s 401us/sample - loss: 0.6766 - acc: 0.7624\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 20s 401us/sample - loss: 0.6422 - acc: 0.7757\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 20s 400us/sample - loss: 0.6034 - acc: 0.7896\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 20s 399us/sample - loss: 0.5719 - acc: 0.7996\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 20s 400us/sample - loss: 0.5450 - acc: 0.8090\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 20s 402us/sample - loss: 0.5150 - acc: 0.8199\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 20s 403us/sample - loss: 0.4967 - acc: 0.8256\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 20s 402us/sample - loss: 0.4701 - acc: 0.8340\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 20s 399us/sample - loss: 0.4416 - acc: 0.8451\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 20s 400us/sample - loss: 0.4236 - acc: 0.8516\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 20s 400us/sample - loss: 0.4026 - acc: 0.8546\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 20s 400us/sample - loss: 0.3816 - acc: 0.8640\n",
            "50000/50000 [==============================] - 8s 154us/sample - loss: 0.2533 - acc: 0.9173\n",
            "\n",
            "Train accuracy: 91.7%\n",
            "10000/10000 [==============================] - 2s 152us/sample - loss: 0.7271 - acc: 0.7700\n",
            "\n",
            "Test accuracy: 77.0%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrQB0sAQU5bC",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "With filters set to 256 and dropout set to 0.4, Training Data Accuracy decreased to 91.7% but Test Data Accuracy increased to 77.0%. We again check if accuracy will still improve as we further increase the dropout value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzQ-WvwXTarK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ce8d5580-eff8-4d5c-d717-7fb98ff20830"
      },
      "source": [
        "# Set filters to 256 and dropout to 0.5\n",
        "run_model(256, 0.5)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_18 (Conv2D)           (None, 30, 30, 256)       7168      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 15, 15, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 13, 13, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 4, 4, 256)         590080    \n",
            "_________________________________________________________________\n",
            "flatten_6 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 10)                40970     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,228,298\n",
            "Trainable params: 1,228,298\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 20s 407us/sample - loss: 1.6071 - acc: 0.4116\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 20s 400us/sample - loss: 1.2289 - acc: 0.5624\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 20s 401us/sample - loss: 1.0586 - acc: 0.6282\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 20s 403us/sample - loss: 0.9463 - acc: 0.6680\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 20s 401us/sample - loss: 0.8647 - acc: 0.6968\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 20s 402us/sample - loss: 0.8052 - acc: 0.7195\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 20s 401us/sample - loss: 0.7494 - acc: 0.7357\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 20s 401us/sample - loss: 0.7115 - acc: 0.7508\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 20s 399us/sample - loss: 0.6708 - acc: 0.7655\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 20s 401us/sample - loss: 0.6375 - acc: 0.7754\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 20s 399us/sample - loss: 0.6044 - acc: 0.7890\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 20s 399us/sample - loss: 0.5737 - acc: 0.7985\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 20s 404us/sample - loss: 0.5490 - acc: 0.8070\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 20s 401us/sample - loss: 0.5276 - acc: 0.8152\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 20s 398us/sample - loss: 0.4978 - acc: 0.8228\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 20s 398us/sample - loss: 0.4802 - acc: 0.8308\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 20s 398us/sample - loss: 0.4593 - acc: 0.8370\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 20s 399us/sample - loss: 0.4439 - acc: 0.8425\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 20s 397us/sample - loss: 0.4222 - acc: 0.8505\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 20s 398us/sample - loss: 0.4099 - acc: 0.8553\n",
            "50000/50000 [==============================] - 8s 154us/sample - loss: 0.2387 - acc: 0.9254\n",
            "\n",
            "Train accuracy: 92.5%\n",
            "10000/10000 [==============================] - 2s 153us/sample - loss: 0.6797 - acc: 0.7773\n",
            "\n",
            "Test accuracy: 77.7%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUprlWHLVBNo",
        "colab_type": "text"
      },
      "source": [
        "With filters set to 256 and dropout set to 0.5, Training Data Accuracy increased to 92.5% and Test Data Accuracy increased to 77.73%. We again check if accuracy will still improve as we further increase the dropout value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik9EHcTQTc9G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e9f8970a-7d7e-4486-ae1d-d3c3c02aa56e"
      },
      "source": [
        "# Set filters to 256 and dropout to 0.6\n",
        "run_model(256, 0.6)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Large dropout rate: 0.6 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_21 (Conv2D)           (None, 30, 30, 256)       7168      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 15, 15, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_22 (Conv2D)           (None, 13, 13, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_23 (Conv2D)           (None, 4, 4, 256)         590080    \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 10)                40970     \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,228,298\n",
            "Trainable params: 1,228,298\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 20s 402us/sample - loss: 1.6563 - acc: 0.3907\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 20s 402us/sample - loss: 1.2721 - acc: 0.5455\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 20s 403us/sample - loss: 1.1122 - acc: 0.6071\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 20s 402us/sample - loss: 1.0098 - acc: 0.6459\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 20s 398us/sample - loss: 0.9411 - acc: 0.6707\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 20s 399us/sample - loss: 0.8790 - acc: 0.6917\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 20s 398us/sample - loss: 0.8335 - acc: 0.7105\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 20s 399us/sample - loss: 0.7928 - acc: 0.7231\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 20s 396us/sample - loss: 0.7652 - acc: 0.7325\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 20s 399us/sample - loss: 0.7396 - acc: 0.7386\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 20s 397us/sample - loss: 0.7013 - acc: 0.7554\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 20s 397us/sample - loss: 0.6863 - acc: 0.7596\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 20s 398us/sample - loss: 0.6618 - acc: 0.7687\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 20s 397us/sample - loss: 0.6381 - acc: 0.7765\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 20s 398us/sample - loss: 0.6236 - acc: 0.7806\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 20s 396us/sample - loss: 0.6076 - acc: 0.7854\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 20s 397us/sample - loss: 0.5886 - acc: 0.7939\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 20s 401us/sample - loss: 0.5666 - acc: 0.8005\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 20s 399us/sample - loss: 0.5480 - acc: 0.8078\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 20s 400us/sample - loss: 0.5401 - acc: 0.8094\n",
            "50000/50000 [==============================] - 8s 153us/sample - loss: 0.3683 - acc: 0.8778\n",
            "\n",
            "Train accuracy: 87.8%\n",
            "10000/10000 [==============================] - 2s 150us/sample - loss: 0.6536 - acc: 0.7772\n",
            "\n",
            "Test accuracy: 77.7%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5ZyMg9mUiMv",
        "colab_type": "text"
      },
      "source": [
        "With filters set to 256 and dropout set to 0.6, Training Data Accuracy decreased to 87.8% and Test Data Accuracy decreased to 77.72%. We take a step back and choose 0.5 as the dropout value since it generated the highest Test Data Accuracy (before it started to decrease)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjZ6aDT4WFtx",
        "colab_type": "text"
      },
      "source": [
        "After hyperparameter tuning, we now train the CNN over **200 epochs**. For every 20th epoch, Training & Test Data Accuracies are generated for evaluation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmoXSPWV0zZP",
        "colab_type": "code",
        "outputId": "0d2102e4-1d01-4211-9fc9-cf54a5acbe45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Set chosen hyperparameter values\n",
        "filters = 256\n",
        "dropout = 0.5\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(filters=filters,\n",
        "                   kernel_size=3,\n",
        "                   activation='relu',\n",
        "                   input_shape=input_shape))\n",
        "model.add(MaxPooling2D(2))\n",
        "model.add(Conv2D(filters=filters,\n",
        "                   kernel_size=3,\n",
        "                   activation='relu'))\n",
        "model.add(MaxPooling2D(2))\n",
        "model.add(Conv2D(filters=filters,\n",
        "                   kernel_size=3,\n",
        "                   activation='relu'))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(dropout))\n",
        "model.add(Dense(num_labels))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "  \n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the CNN\n",
        "i = 1\n",
        "epoch = 20\n",
        "epoch_num = []\n",
        "train_acc = []\n",
        "test_acc = []\n",
        "while i <= 10:\n",
        "  epoch_num.append(epoch * i)\n",
        "  model.fit(x_train, y_train, epochs=20, batch_size=128)\n",
        "  train_score = model.evaluate(x_train, y_train, batch_size=128)\n",
        "  print(\"\\nTrain accuracy: %.1f%%\" % (100.0 * train_score[1]))\n",
        "  train_acc.append(train_score[1])\n",
        "  test_score = model.evaluate(x_test, y_test, batch_size=128)\n",
        "  print(\"\\nTest accuracy: %.1f%%\" % (100.0 * test_score[1]))\n",
        "  test_acc.append(test_score[1])\n",
        "  i = i + 1"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_24 (Conv2D)           (None, 30, 30, 256)       7168      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_16 (MaxPooling (None, 15, 15, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 13, 13, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 4, 4, 256)         590080    \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                40970     \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,228,298\n",
            "Trainable params: 1,228,298\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 20s 405us/sample - loss: 1.6004 - acc: 0.4104\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 20s 400us/sample - loss: 1.2173 - acc: 0.5642\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 20s 400us/sample - loss: 1.0531 - acc: 0.6299\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 20s 403us/sample - loss: 0.9408 - acc: 0.6717\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 20s 402us/sample - loss: 0.8566 - acc: 0.7020\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 20s 401us/sample - loss: 0.7997 - acc: 0.7199\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 20s 402us/sample - loss: 0.7420 - acc: 0.7417\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 20s 403us/sample - loss: 0.6997 - acc: 0.7575\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 20s 401us/sample - loss: 0.6611 - acc: 0.7701\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 20s 402us/sample - loss: 0.6286 - acc: 0.7799\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 20s 403us/sample - loss: 0.5883 - acc: 0.7933\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 20s 401us/sample - loss: 0.5651 - acc: 0.8039\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 20s 400us/sample - loss: 0.5438 - acc: 0.8092\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 20s 401us/sample - loss: 0.5210 - acc: 0.8167\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 20s 400us/sample - loss: 0.4990 - acc: 0.8269\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 20s 400us/sample - loss: 0.4738 - acc: 0.8320\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 20s 401us/sample - loss: 0.4578 - acc: 0.8395\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 20s 400us/sample - loss: 0.4350 - acc: 0.8469\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 20s 398us/sample - loss: 0.4205 - acc: 0.8517\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 20s 400us/sample - loss: 0.4061 - acc: 0.8547\n",
            "50000/50000 [==============================] - 8s 154us/sample - loss: 0.2217 - acc: 0.9364\n",
            "\n",
            "Train accuracy: 93.6%\n",
            "10000/10000 [==============================] - 2s 155us/sample - loss: 0.6612 - acc: 0.7840\n",
            "\n",
            "Test accuracy: 78.4%\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 20s 400us/sample - loss: 0.3928 - acc: 0.8599\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 20s 401us/sample - loss: 0.3719 - acc: 0.8682\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 20s 400us/sample - loss: 0.3634 - acc: 0.8709\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 20s 400us/sample - loss: 0.3507 - acc: 0.8750\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 20s 400us/sample - loss: 0.3373 - acc: 0.8800\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 20s 399us/sample - loss: 0.3234 - acc: 0.8845\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 20s 400us/sample - loss: 0.3163 - acc: 0.8885\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 20s 399us/sample - loss: 0.3081 - acc: 0.8888\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 20s 401us/sample - loss: 0.3022 - acc: 0.8921\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 20s 395us/sample - loss: 0.2869 - acc: 0.8976\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 19s 389us/sample - loss: 0.2727 - acc: 0.9037\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 20s 392us/sample - loss: 0.2676 - acc: 0.9042\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 20s 392us/sample - loss: 0.2615 - acc: 0.9056\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 20s 392us/sample - loss: 0.2675 - acc: 0.9031\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 20s 398us/sample - loss: 0.2498 - acc: 0.9102\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 20s 398us/sample - loss: 0.2466 - acc: 0.9106\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 20s 391us/sample - loss: 0.2430 - acc: 0.9132\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 20s 391us/sample - loss: 0.2373 - acc: 0.9158\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 20s 392us/sample - loss: 0.2310 - acc: 0.9169\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 20s 395us/sample - loss: 0.2235 - acc: 0.9198\n",
            "50000/50000 [==============================] - 8s 151us/sample - loss: 0.0787 - acc: 0.9796\n",
            "\n",
            "Train accuracy: 98.0%\n",
            "10000/10000 [==============================] - 2s 152us/sample - loss: 0.8345 - acc: 0.7798\n",
            "\n",
            "Test accuracy: 78.0%\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 20s 392us/sample - loss: 0.2225 - acc: 0.9201\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 20s 392us/sample - loss: 0.2133 - acc: 0.9237\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 20s 393us/sample - loss: 0.2062 - acc: 0.9263\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 20s 394us/sample - loss: 0.2114 - acc: 0.9246\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 20s 394us/sample - loss: 0.2093 - acc: 0.9265\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 20s 394us/sample - loss: 0.1917 - acc: 0.9316\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 20s 393us/sample - loss: 0.1971 - acc: 0.9294\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 20s 393us/sample - loss: 0.1959 - acc: 0.9311\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 20s 394us/sample - loss: 0.1879 - acc: 0.9317\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 20s 393us/sample - loss: 0.1910 - acc: 0.9317\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 20s 396us/sample - loss: 0.1845 - acc: 0.9344\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 20s 395us/sample - loss: 0.1835 - acc: 0.9347\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 20s 392us/sample - loss: 0.1825 - acc: 0.9345\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 20s 392us/sample - loss: 0.1854 - acc: 0.9336\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 20s 394us/sample - loss: 0.1757 - acc: 0.9373\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 20s 395us/sample - loss: 0.1742 - acc: 0.9375\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 20s 393us/sample - loss: 0.1759 - acc: 0.9371\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 20s 393us/sample - loss: 0.1683 - acc: 0.9399\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 20s 394us/sample - loss: 0.1635 - acc: 0.9436\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 20s 395us/sample - loss: 0.1699 - acc: 0.9407\n",
            "50000/50000 [==============================] - 8s 152us/sample - loss: 0.0302 - acc: 0.9939\n",
            "\n",
            "Train accuracy: 99.4%\n",
            "10000/10000 [==============================] - 2s 153us/sample - loss: 0.9316 - acc: 0.7852\n",
            "\n",
            "Test accuracy: 78.5%\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 20s 394us/sample - loss: 0.1585 - acc: 0.9437\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 20s 396us/sample - loss: 0.1563 - acc: 0.9448\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 20s 396us/sample - loss: 0.1547 - acc: 0.9448\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 20s 395us/sample - loss: 0.1575 - acc: 0.9456\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 20s 395us/sample - loss: 0.1565 - acc: 0.9455\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 20s 400us/sample - loss: 0.1533 - acc: 0.9456\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 20s 396us/sample - loss: 0.1535 - acc: 0.9460\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 20s 395us/sample - loss: 0.1408 - acc: 0.9502\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 20s 396us/sample - loss: 0.1515 - acc: 0.9463\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 20s 396us/sample - loss: 0.1504 - acc: 0.9478\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 20s 398us/sample - loss: 0.1399 - acc: 0.9508\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 20s 394us/sample - loss: 0.1434 - acc: 0.9505\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 20s 395us/sample - loss: 0.1520 - acc: 0.9473\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 20s 395us/sample - loss: 0.1450 - acc: 0.9505\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 20s 396us/sample - loss: 0.1331 - acc: 0.9525\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 20s 394us/sample - loss: 0.1423 - acc: 0.9503\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 20s 395us/sample - loss: 0.1423 - acc: 0.9505\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 20s 397us/sample - loss: 0.1356 - acc: 0.9526\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 20s 396us/sample - loss: 0.1417 - acc: 0.9515\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 20s 396us/sample - loss: 0.1292 - acc: 0.9540\n",
            "50000/50000 [==============================] - 8s 152us/sample - loss: 0.0202 - acc: 0.9958\n",
            "\n",
            "Train accuracy: 99.6%\n",
            "10000/10000 [==============================] - 2s 154us/sample - loss: 1.0674 - acc: 0.7856\n",
            "\n",
            "Test accuracy: 78.6%\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 20s 401us/sample - loss: 0.1386 - acc: 0.9521\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 20s 397us/sample - loss: 0.1282 - acc: 0.9559\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 20s 395us/sample - loss: 0.1465 - acc: 0.9498\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 20s 395us/sample - loss: 0.1266 - acc: 0.9564\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 20s 396us/sample - loss: 0.1289 - acc: 0.9557\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 20s 397us/sample - loss: 0.1275 - acc: 0.9566\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 20s 395us/sample - loss: 0.1244 - acc: 0.9577\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 20s 395us/sample - loss: 0.1307 - acc: 0.9559\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 20s 395us/sample - loss: 0.1361 - acc: 0.9530\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 20s 396us/sample - loss: 0.1295 - acc: 0.9557\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 20s 395us/sample - loss: 0.1244 - acc: 0.9567\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 20s 393us/sample - loss: 0.1245 - acc: 0.9579\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 20s 403us/sample - loss: 0.1251 - acc: 0.9576\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 20s 404us/sample - loss: 0.1183 - acc: 0.9593\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 20s 405us/sample - loss: 0.1178 - acc: 0.9599\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 20s 396us/sample - loss: 0.1245 - acc: 0.9587\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 20s 392us/sample - loss: 0.1242 - acc: 0.9563\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 20s 396us/sample - loss: 0.1231 - acc: 0.9579\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 20s 390us/sample - loss: 0.1180 - acc: 0.9589\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 20s 391us/sample - loss: 0.1191 - acc: 0.9595\n",
            "50000/50000 [==============================] - 7s 149us/sample - loss: 0.0153 - acc: 0.9973\n",
            "\n",
            "Train accuracy: 99.7%\n",
            "10000/10000 [==============================] - 2s 150us/sample - loss: 1.0908 - acc: 0.7829\n",
            "\n",
            "Test accuracy: 78.3%\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 19s 389us/sample - loss: 0.1217 - acc: 0.9584\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 20s 390us/sample - loss: 0.1199 - acc: 0.9584\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 20s 390us/sample - loss: 0.1141 - acc: 0.9609\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 20s 390us/sample - loss: 0.1134 - acc: 0.9622\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 20s 390us/sample - loss: 0.1168 - acc: 0.9601\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 20s 392us/sample - loss: 0.1195 - acc: 0.9597\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 20s 396us/sample - loss: 0.1131 - acc: 0.9615\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 20s 396us/sample - loss: 0.1133 - acc: 0.9610\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 19s 389us/sample - loss: 0.1160 - acc: 0.9609\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 20s 393us/sample - loss: 0.1158 - acc: 0.9610\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 19s 389us/sample - loss: 0.1121 - acc: 0.9622\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 19s 387us/sample - loss: 0.1175 - acc: 0.9609\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 19s 385us/sample - loss: 0.1114 - acc: 0.9622\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 19s 388us/sample - loss: 0.1103 - acc: 0.9630\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 20s 398us/sample - loss: 0.1163 - acc: 0.9611\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 20s 402us/sample - loss: 0.1109 - acc: 0.9622\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 20s 397us/sample - loss: 0.1040 - acc: 0.9642\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 20s 395us/sample - loss: 0.1061 - acc: 0.9632\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 19s 389us/sample - loss: 0.1180 - acc: 0.9605\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 20s 399us/sample - loss: 0.1016 - acc: 0.9657\n",
            "50000/50000 [==============================] - 8s 150us/sample - loss: 0.0087 - acc: 0.9985\n",
            "\n",
            "Train accuracy: 99.8%\n",
            "10000/10000 [==============================] - 1s 149us/sample - loss: 1.1879 - acc: 0.7774\n",
            "\n",
            "Test accuracy: 77.7%\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 20s 392us/sample - loss: 0.1075 - acc: 0.9624\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 20s 396us/sample - loss: 0.1055 - acc: 0.9635\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 20s 396us/sample - loss: 0.1080 - acc: 0.9641\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 19s 389us/sample - loss: 0.1051 - acc: 0.9650\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 20s 401us/sample - loss: 0.1110 - acc: 0.9631\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 20s 395us/sample - loss: 0.1144 - acc: 0.9619\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 20s 390us/sample - loss: 0.1084 - acc: 0.9644\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 20s 395us/sample - loss: 0.1088 - acc: 0.9638\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 20s 393us/sample - loss: 0.1042 - acc: 0.9652\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 20s 393us/sample - loss: 0.1031 - acc: 0.9644\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 20s 399us/sample - loss: 0.0987 - acc: 0.9671\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 20s 398us/sample - loss: 0.1017 - acc: 0.9667\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 20s 392us/sample - loss: 0.1005 - acc: 0.9654\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 20s 391us/sample - loss: 0.0981 - acc: 0.9672\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 19s 387us/sample - loss: 0.1022 - acc: 0.9666\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 19s 389us/sample - loss: 0.1050 - acc: 0.9651\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 19s 387us/sample - loss: 0.1018 - acc: 0.9660\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 20s 395us/sample - loss: 0.1017 - acc: 0.9666\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 20s 402us/sample - loss: 0.1033 - acc: 0.9670\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 20s 398us/sample - loss: 0.0997 - acc: 0.9671\n",
            "50000/50000 [==============================] - 8s 159us/sample - loss: 0.0053 - acc: 0.9989\n",
            "\n",
            "Train accuracy: 99.9%\n",
            "10000/10000 [==============================] - 2s 158us/sample - loss: 1.2695 - acc: 0.7829\n",
            "\n",
            "Test accuracy: 78.3%\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 20s 400us/sample - loss: 0.0953 - acc: 0.9680\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 20s 390us/sample - loss: 0.1026 - acc: 0.9670\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 20s 395us/sample - loss: 0.0965 - acc: 0.9679\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 20s 393us/sample - loss: 0.0958 - acc: 0.9682\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 20s 396us/sample - loss: 0.0980 - acc: 0.9676\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 20s 399us/sample - loss: 0.0971 - acc: 0.9676\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 19s 389us/sample - loss: 0.0973 - acc: 0.9679\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 19s 386us/sample - loss: 0.1033 - acc: 0.9664\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 19s 388us/sample - loss: 0.1022 - acc: 0.9661\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 19s 387us/sample - loss: 0.0921 - acc: 0.9701\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 20s 392us/sample - loss: 0.1000 - acc: 0.9670\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 20s 390us/sample - loss: 0.0934 - acc: 0.9697\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 19s 385us/sample - loss: 0.0949 - acc: 0.9691\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 20s 402us/sample - loss: 0.1020 - acc: 0.9678\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 20s 393us/sample - loss: 0.0960 - acc: 0.9679\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 19s 389us/sample - loss: 0.0892 - acc: 0.9708\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 20s 393us/sample - loss: 0.0941 - acc: 0.9693\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 20s 390us/sample - loss: 0.0904 - acc: 0.9699\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 20s 392us/sample - loss: 0.0958 - acc: 0.9689\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 20s 395us/sample - loss: 0.0972 - acc: 0.9682\n",
            "50000/50000 [==============================] - 8s 153us/sample - loss: 0.0074 - acc: 0.9984\n",
            "\n",
            "Train accuracy: 99.8%\n",
            "10000/10000 [==============================] - 1s 148us/sample - loss: 1.3131 - acc: 0.7772\n",
            "\n",
            "Test accuracy: 77.7%\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 19s 389us/sample - loss: 0.0982 - acc: 0.9681\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 20s 402us/sample - loss: 0.0950 - acc: 0.9694\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 20s 398us/sample - loss: 0.0888 - acc: 0.9707\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 19s 389us/sample - loss: 0.0886 - acc: 0.9723\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 20s 392us/sample - loss: 0.0886 - acc: 0.9716\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 20s 390us/sample - loss: 0.0869 - acc: 0.9718\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 20s 399us/sample - loss: 0.0844 - acc: 0.9722\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 20s 395us/sample - loss: 0.0975 - acc: 0.9686\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 20s 393us/sample - loss: 0.0910 - acc: 0.9715\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 20s 402us/sample - loss: 0.0956 - acc: 0.9693\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 20s 398us/sample - loss: 0.0935 - acc: 0.9689\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 20s 399us/sample - loss: 0.0926 - acc: 0.9704\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 20s 394us/sample - loss: 0.0953 - acc: 0.9694\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 20s 394us/sample - loss: 0.0967 - acc: 0.9697\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 20s 394us/sample - loss: 0.0914 - acc: 0.9704\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 20s 399us/sample - loss: 0.0888 - acc: 0.9720\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 20s 397us/sample - loss: 0.0864 - acc: 0.9725\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 20s 398us/sample - loss: 0.0994 - acc: 0.9685\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 20s 400us/sample - loss: 0.0913 - acc: 0.9701\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 20s 397us/sample - loss: 0.0907 - acc: 0.9716\n",
            "50000/50000 [==============================] - 8s 152us/sample - loss: 0.0043 - acc: 0.9992\n",
            "\n",
            "Train accuracy: 99.9%\n",
            "10000/10000 [==============================] - 2s 153us/sample - loss: 1.4309 - acc: 0.7828\n",
            "\n",
            "Test accuracy: 78.3%\n",
            "Epoch 1/20\n",
            "50000/50000 [==============================] - 20s 397us/sample - loss: 0.0858 - acc: 0.9713\n",
            "Epoch 2/20\n",
            "50000/50000 [==============================] - 20s 391us/sample - loss: 0.0860 - acc: 0.9723\n",
            "Epoch 3/20\n",
            "50000/50000 [==============================] - 20s 399us/sample - loss: 0.0943 - acc: 0.9695\n",
            "Epoch 4/20\n",
            "50000/50000 [==============================] - 20s 393us/sample - loss: 0.0914 - acc: 0.9705\n",
            "Epoch 5/20\n",
            "50000/50000 [==============================] - 20s 401us/sample - loss: 0.0837 - acc: 0.9724\n",
            "Epoch 6/20\n",
            "50000/50000 [==============================] - 20s 393us/sample - loss: 0.0900 - acc: 0.9712\n",
            "Epoch 7/20\n",
            "50000/50000 [==============================] - 19s 386us/sample - loss: 0.0913 - acc: 0.9708\n",
            "Epoch 8/20\n",
            "50000/50000 [==============================] - 19s 388us/sample - loss: 0.0909 - acc: 0.9716\n",
            "Epoch 9/20\n",
            "50000/50000 [==============================] - 19s 389us/sample - loss: 0.0872 - acc: 0.9728\n",
            "Epoch 10/20\n",
            "50000/50000 [==============================] - 19s 389us/sample - loss: 0.0879 - acc: 0.9725\n",
            "Epoch 11/20\n",
            "50000/50000 [==============================] - 20s 392us/sample - loss: 0.0903 - acc: 0.9710\n",
            "Epoch 12/20\n",
            "50000/50000 [==============================] - 19s 389us/sample - loss: 0.0887 - acc: 0.9719\n",
            "Epoch 13/20\n",
            "50000/50000 [==============================] - 19s 389us/sample - loss: 0.0886 - acc: 0.9713\n",
            "Epoch 14/20\n",
            "50000/50000 [==============================] - 20s 392us/sample - loss: 0.0905 - acc: 0.9719\n",
            "Epoch 15/20\n",
            "50000/50000 [==============================] - 20s 390us/sample - loss: 0.0824 - acc: 0.9739\n",
            "Epoch 16/20\n",
            "50000/50000 [==============================] - 20s 391us/sample - loss: 0.0984 - acc: 0.9699\n",
            "Epoch 17/20\n",
            "50000/50000 [==============================] - 20s 393us/sample - loss: 0.0823 - acc: 0.9736\n",
            "Epoch 18/20\n",
            "50000/50000 [==============================] - 20s 392us/sample - loss: 0.0858 - acc: 0.9731\n",
            "Epoch 19/20\n",
            "50000/50000 [==============================] - 20s 393us/sample - loss: 0.0733 - acc: 0.9757\n",
            "Epoch 20/20\n",
            "50000/50000 [==============================] - 19s 389us/sample - loss: 0.0843 - acc: 0.9736\n",
            "50000/50000 [==============================] - 8s 150us/sample - loss: 0.0026 - acc: 0.9996\n",
            "\n",
            "Train accuracy: 100.0%\n",
            "10000/10000 [==============================] - 2s 152us/sample - loss: 1.4698 - acc: 0.7857\n",
            "\n",
            "Test accuracy: 78.6%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YntOxt1uR_UM",
        "colab_type": "text"
      },
      "source": [
        "The model's Training and Test Data Accuracy is plotted against the number of epochs performed during training. Looking at the plot, it can be observed that **as the number of epochs increase, Training Data Accuracy increases**. On the other hand, **Test Data Accuracy is fluctuating around 0.77-0.78**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSQ8meCvVUO2",
        "colab_type": "code",
        "outputId": "35aa12cf-503c-45ac-9f03-7d6d6eff3ff6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "# Generate plot showing Training & Test Data Accuracy\n",
        "plt.plot(epoch_num, train_acc)\n",
        "plt.plot(epoch_num, test_acc)\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LT74siJUVWx2",
        "colab_type": "code",
        "outputId": "d69a63e2-f7bb-4de6-ad6c-db8140679003",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "# Generate table showing Training & Test Data Accuracy\n",
        "df = pd.DataFrame(pd.concat([pd.Series(epoch_num),pd.Series(train_acc),pd.Series(test_acc)], axis=1))\n",
        "df.columns = ['Epoch','Training Data Accuracy','Test Data Acccuracy']\n",
        "df"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Data Accuracy</th>\n",
              "      <th>Test Data Acccuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20</td>\n",
              "      <td>0.93638</td>\n",
              "      <td>0.7840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>40</td>\n",
              "      <td>0.97960</td>\n",
              "      <td>0.7798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>60</td>\n",
              "      <td>0.99386</td>\n",
              "      <td>0.7852</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>80</td>\n",
              "      <td>0.99576</td>\n",
              "      <td>0.7856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100</td>\n",
              "      <td>0.99730</td>\n",
              "      <td>0.7829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>120</td>\n",
              "      <td>0.99850</td>\n",
              "      <td>0.7774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>140</td>\n",
              "      <td>0.99890</td>\n",
              "      <td>0.7829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>160</td>\n",
              "      <td>0.99844</td>\n",
              "      <td>0.7772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>180</td>\n",
              "      <td>0.99924</td>\n",
              "      <td>0.7828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>200</td>\n",
              "      <td>0.99964</td>\n",
              "      <td>0.7857</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Epoch  Training Data Accuracy  Test Data Acccuracy\n",
              "0     20                 0.93638               0.7840\n",
              "1     40                 0.97960               0.7798\n",
              "2     60                 0.99386               0.7852\n",
              "3     80                 0.99576               0.7856\n",
              "4    100                 0.99730               0.7829\n",
              "5    120                 0.99850               0.7774\n",
              "6    140                 0.99890               0.7829\n",
              "7    160                 0.99844               0.7772\n",
              "8    180                 0.99924               0.7828\n",
              "9    200                 0.99964               0.7857"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBnIgqY4b08h",
        "colab_type": "text"
      },
      "source": [
        "**CNN was able to generate higher Test Data Accuracy than MLP (MLP @ 52.89%, CNN @ 78.57%)**. CNN's method of extracting features from the image (Conv2D, Max Pooling) allows **highly distinctive areas of the image to standout**. This ability to develop an internal representation of a two-dimensional image makes CNN more efficient at training and ultimately better at making predictions than MLP when it comes to **image data**."
      ]
    }
  ]
}